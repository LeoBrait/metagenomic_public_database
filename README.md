# BIOME METAGENOMIC PUBLIC DATABASE

**warning: None of the present data should be shared or used without the consent of the supervisor Dr. Pedro Meirelles.**  
**warning: None of the present data should be shared or used without the consent of the supervisor Dr. Pedro Meirelles.**  
**warning: None of the present data should be shared or used without the consent of the supervisor Dr. Pedro Meirelles.**  
## Introduction  
  
The BIOME metagenomic public database contains 5272 metagenomic samples collected from MG-RAST and NCBI databases. The samples were recategorized based on two methods, the authoral BIOME classification and the IUCN classification.  
These datbase comprimises other works of the lab, such as:
- [Aquifers Landscapes](https://github.com/MeirellesLab/aquifer_metagenomes)
- [New Microbial Keystones](https://github.com/MeirellesLab/keystones_paper)

## Data organization
- **The [data_processing](data_processing/) contains step-by-step used to process the data.**  
    - The data_processing folder is procedimental and used by the scripts to produce the ready-to-use data contained in all cited bellow.
    For more Details, please check the [readme](data_processing/README.md) file.  
- The [annotated_metagenomes](annotated_metagenomes/) contains the taxonomic relative and absolute abundance matrices generated by Kraken2 using the standard and Biome database.   
- The [metadata](metadata/) contains the BIOME and IUCN classifications of these samples.   
- The [summaries](summaries/) folder contains information about the samples, such as the number of reads, GC content, etc.

## Procediments and script order
This database started as a coarse curatory of the mg-rast metagenomic samples followed by a fine and detailed reclassification. The coarse classification was done in the seek of short-reads metagenomes from natural environments that could be classified in life-style, ecosystem and habitats. The fine and detailed reclassification used the same principles, but more accurate. After the metadata curatory....


1. Metadata treatment
    
-  The first script [split_tables.R](R/split_tables.R) gather the coarse the first [coarse classification](data_processing/01_original_data/coarse_classification.csv) + its respective [original metadatada from Mg-rast](data_processing/01_original_data/mgrast_metadata.csv) and produces a [preprocessed metadata](data_processing/01_original_data/preprocessed_metadata.csv). This preprocessed metadta is then splited by mg-rast biome classification in the folder [02_dismembered_tables](data_processing/02_dismembered_tables/) to facilitate the work in a fine labeling. To run it, just type:

```bash
Rscript R/split_tables.R
```

- The splited tables from [02_dismembered_tables](data_processing/02_dismembered_tables/) were manually grouped by themes in the folder [03_maunual_labeling](data_processing/03_manual_labeling/). There we executed the fine and detailed classification.
- Completed the manual refinement of the data, we proced

## Troubleshooting



























































